<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="Cache-control" content="no-cache, no-store, must-revalidate">
  <meta http-equiv="Pragma" content="no-cache">
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
  <title>Face Landmarker</title>

  <link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
  <script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
</head>
<body>
  <h1>Face Landmark Detection with MediaPipe</h1>

  <section id="demos">
    <div id="liveView" class="videoView">
      <div style="position: relative;">
        <!-- カメラ映像 -->
        <video id="webcam" autoplay playsinline style="position: absolute; width: 100%; height: 100%;"></video>
        <!-- ランドマーク描画用キャンバス -->
        <canvas class="output_canvas" id="output_canvas" style="position: absolute; left: 0px; top: 0px;"></canvas>
      </div>
    </div>
    <div class="blend-shapes">
      <ul class="blend-shapes-list" id="video-blend-shapes"></ul>
    </div>
  </section>

  <!-- 必要なJavaScriptライブラリ -->
  <script type="module">
    import { FaceLandmarker, FilesetResolver } from 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3';

    // FaceLandmarkerとビデオの設定
    const videoElement = document.getElementById('webcam');
    const canvasElement = document.getElementById('output_canvas');
    const canvasCtx = canvasElement.getContext('2d');

    async function setupFaceLandmarker() {
      const vision = await FilesetResolver.forVisionTasks(
        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3'
      );

      const faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_landmark_model/face_landmark_model.task'
        },
        outputFaceBlendshapes: true,
        numFaces: 1
      });

      // ビデオの設定
      navigator.mediaDevices.getUserMedia({ video: true })
        .then((stream) => {
          videoElement.srcObject = stream;
          videoElement.onloadedmetadata = () => {
            videoElement.play();
          };
        });

      // フレームごとに処理
      videoElement.addEventListener('loadeddata', async () => {
        while (true) {
          await faceLandmarker.detectForVideo(videoElement, (results) => {
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            if (results.faceLandmarks) {
              for (const landmarks of results.faceLandmarks) {
                for (const landmark of landmarks) {
                  canvasCtx.beginPath();
                  canvasCtx.arc(landmark.x * canvasElement.width, landmark.y * canvasElement.height, 2, 0, 2 * Math.PI);
                  canvasCtx.fill();
                }
              }
            }
          });
          await new Promise((resolve) => setTimeout(resolve, 30)); // 30ms待機して次のフレームへ
        }
      });
    }

    setupFaceLandmarker();
  </script>
</body>
</html>

